{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Soundnet to Keras\n",
    "\n",
    "Unfortunately the Tensorflow implementation (https://github.com/eborboihuc/SoundNet-tensorflow) of Soundnet is abit hard to work with in Keras. \n",
    "\n",
    "Let's see if we can interorgate it to create our own Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Conv2D, MaxPooling2D, ZeroPadding2D, Activation\n",
    "from keras.activations import relu \n",
    "from keras.models import Model as KModel\n",
    "\n",
    "import model as SoundNet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Understand the original model by looking at code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained weights from here https://drive.google.com/uc?export=download&id=0B9wE6h4m--wjR015M1RLZW45OEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "G_name = './models/sound8.npy'\n",
    "param_G = np.load(G_name, encoding='latin1').item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1', 'conv3', 'conv2', 'conv8_2', 'conv5', 'conv7', 'conv8', 'conv4', 'conv6'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_G.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys seem to line up with the names for each model layer:\n",
    "![from soundnet](https://camo.githubusercontent.com/0b88af5c13ba987a17dcf90cd58816cf8ef04554/687474703a2f2f70726f6a656374732e637361696c2e6d69742e6564752f736f756e646e65742f736f756e646e65742e6a7067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta': array([ 0.22135185,  0.0341051 ,  0.18717989,  0.00313667,  0.09816235,\n",
       "        -0.01616378,  0.48686007,  0.13595471,  0.27616981,  0.03256222,\n",
       "         0.58677894,  0.2408203 ,  0.0112493 ,  0.30446413,  0.23332365,\n",
       "         0.34096041], dtype=float32),\n",
       " 'biases': array([  5.22947684e-02,  -3.40161085e-01,   1.38327324e+00,\n",
       "          3.64338547e-01,  -3.26040685e-01,   1.79568276e-01,\n",
       "          6.42116740e-02,  -1.03648205e-03,   1.81802064e-01,\n",
       "          1.18660912e-01,  -3.31185043e-01,  -5.57779595e-02,\n",
       "          5.85727729e-02,   7.62460768e-01,   8.31446290e-01,\n",
       "          4.92918462e-01], dtype=float32),\n",
       " 'gamma': array([ 0.67092448,  0.70485812,  1.07762814,  1.07327878,  0.99859923,\n",
       "         1.43394423,  0.98132694,  0.82170153,  1.76054716,  1.30240929,\n",
       "         0.61374092,  0.69179982,  1.39582741,  0.89855939,  0.78170842,\n",
       "         0.88884467], dtype=float32),\n",
       " 'mean': array([-0.25211978,  3.3069694 ,  1.29265058,  0.3468363 , -7.58555794,\n",
       "        -0.4582119 ,  0.36731982,  0.54561132,  0.08063642,  0.20060934,\n",
       "        -0.39500237,  0.4565326 , -0.47915456,  0.28680989,  1.13165963,\n",
       "         0.64741123], dtype=float32),\n",
       " 'var': array([ 25892.19140625,  28977.63671875,   9814.6171875 ,  27940.69335938,\n",
       "         52304.66796875,  34629.9140625 ,  24162.2578125 ,  37237.19921875,\n",
       "         38663.5234375 ,   5816.80810547,    764.2232666 ,  17119.06835938,\n",
       "         45902.73828125,  14777.60449219,  21598.45507812,   1602.12036133], dtype=float32),\n",
       " 'weights': array([[[[-0.41206488,  0.33841759, -0.05745466, ..., -0.12416738,\n",
       "           -0.1477133 , -0.14983156]]],\n",
       " \n",
       " \n",
       "        [[[-0.04306516,  0.25966772, -0.02400756, ...,  0.03312754,\n",
       "           -0.09598298, -0.03149422]]],\n",
       " \n",
       " \n",
       "        [[[-0.25591961,  0.33929232, -0.14202501, ...,  0.02946956,\n",
       "           -0.12830754,  0.23054236]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[-0.02689798, -0.08974042, -0.025899  , ..., -0.21152316,\n",
       "           -0.15769666,  0.01884886]]],\n",
       " \n",
       " \n",
       "        [[[-0.04064217, -0.09046322,  0.01709429, ..., -0.13511573,\n",
       "           -0.11740343, -0.02732497]]],\n",
       " \n",
       " \n",
       "        [[[-0.16210946, -0.04213618,  0.02096949, ..., -0.18609105,\n",
       "           -0.18389386, -0.03830315]]]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_G['conv1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each name seems to contain the weights for the individual layer. \n",
    "\n",
    "Below is the code from the tensorflow `model.py` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't run this cell! It's just so we can see the code\n",
    "def add_generator(self, name_scope='SoundNet'):\n",
    "\n",
    "    with tf.variable_scope(name_scope) as scope:\n",
    "\n",
    "        self.layers = {}\n",
    "        # Stream one: conv1 ~ conv7\n",
    "\n",
    "        self.layers[1] = conv2d(self.sound_input_placeholder, 1, 16, k_h=64, d_h=2, p_h=32, name_scope='conv1')\n",
    "\n",
    "        self.layers[2] = batch_norm(self.layers[1], 16, self.config['eps'], name_scope='conv1')\n",
    "\n",
    "        self.layers[3] = relu(self.layers[2], name_scope='conv1')\n",
    "\n",
    "        self.layers[4] = maxpool(self.layers[3], k_h=8, d_h=8, name_scope='conv1')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[5] = conv2d(self.layers[4], 16, 32, k_h=32, d_h=2, p_h=16, name_scope='conv2')\n",
    "\n",
    "        self.layers[6] = batch_norm(self.layers[5], 32, self.config['eps'], name_scope='conv2')\n",
    "\n",
    "        self.layers[7] = relu(self.layers[6], name_scope='conv2')\n",
    "\n",
    "        self.layers[8] = maxpool(self.layers[7], k_h=8, d_h=8, name_scope='conv2')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[9] = conv2d(self.layers[8], 32, 64, k_h=16, d_h=2, p_h=8, name_scope='conv3')\n",
    "\n",
    "        self.layers[10] = batch_norm(self.layers[9], 64, self.config['eps'], name_scope='conv3')\n",
    "\n",
    "        self.layers[11] = relu(self.layers[10], name_scope='conv3')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[12] = conv2d(self.layers[11], 64, 128, k_h=8, d_h=2, p_h=4, name_scope='conv4')\n",
    "\n",
    "        self.layers[13] = batch_norm(self.layers[12], 128, self.config['eps'], name_scope='conv4')\n",
    "\n",
    "        self.layers[14] = relu(self.layers[13], name_scope='conv4')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[15] = conv2d(self.layers[14], 128, 256, k_h=4, d_h=2, p_h=2, name_scope='conv5')\n",
    "\n",
    "        self.layers[16] = batch_norm(self.layers[15], 256, self.config['eps'], name_scope='conv5')\n",
    "\n",
    "        self.layers[17] = relu(self.layers[16], name_scope='conv5')\n",
    "\n",
    "        self.layers[18] = maxpool(self.layers[17], k_h=4, d_h=4, name_scope='conv5')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[19] = conv2d(self.layers[18], 256, 512, k_h=4, d_h=2, p_h=2, name_scope='conv6')\n",
    "\n",
    "        self.layers[20] = batch_norm(self.layers[19], 512, self.config['eps'], name_scope='conv6')\n",
    "\n",
    "        self.layers[21] = relu(self.layers[20], name_scope='conv6')\n",
    "\n",
    "\n",
    "\n",
    "        self.layers[22] = conv2d(self.layers[21], 512, 1024, k_h=4, d_h=2, p_h=2, name_scope='conv7')\n",
    "\n",
    "        self.layers[23] = batch_norm(self.layers[22], 1024, self.config['eps'], name_scope='conv7')\n",
    "\n",
    "        self.layers[24] = relu(self.layers[23], name_scope='conv7')\n",
    "\n",
    "\n",
    "\n",
    "        # Split one: conv8, conv8_2\n",
    "\n",
    "        self.layers[25] = conv2d(self.layers[24], 1024, 1000, k_h=8, d_h=2, name_scope='conv8')\n",
    "\n",
    "        self.layers[26] = conv2d(self.layers[24], 1024, 401, k_h=8, d_h=2, name_scope='conv8_2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a pretty standard conv net architecture, but these helper functions need to be inspected. \n",
    "Let's check-out `ops.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow version of NIPS2016 soundnet\n",
    "import tensorflow as tf\n",
    "\n",
    "def conv2d(prev_layer, in_ch, out_ch, k_h=1, k_w=1, d_h=1, d_w=1, p_h=0, p_w=0, pad='VALID', name_scope='conv'):\n",
    "    with tf.variable_scope(name_scope) as scope:\n",
    "        # h x w x input_channel x output_channel\n",
    "        w_conv = tf.get_variable('weights', [k_h, k_w, in_ch, out_ch], \n",
    "                initializer=tf.truncated_normal_initializer(0.0, stddev=0.01))\n",
    "\n",
    "        b_conv = tf.get_variable('biases', [out_ch], \n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        padded_input = tf.pad(prev_layer, [[0, 0], [p_h, p_h], [p_w, p_w], [0, 0]], \"CONSTANT\") if pad == 'VALID' \\\n",
    "                else prev_layer\n",
    "\n",
    "        output = tf.nn.conv2d(padded_input, w_conv, \n",
    "                [1, d_h, d_w, 1], padding=pad, name='z') + b_conv\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a bunch of strange things going on here... \n",
    "\n",
    "However, it also looks pretty standard, we have the conv weights and biases that we'll need to get from the params, we have a padding layer. There is also some weird `if`, `else` syntax going on. \n",
    "\n",
    "It looks like the trickiest thing will be making sure we don't get the height and width mixed up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(prev_layer, out_ch, eps, name_scope='conv'):\n",
    "    with tf.variable_scope(name_scope) as scope:\n",
    "        #mu_conv, var_conv = tf.nn.moments(prev_layer, [0, 1, 2], keep_dims=False)\n",
    "        mu_conv = tf.get_variable('mean', [out_ch], \n",
    "            initializer=tf.constant_initializer(0))\n",
    "        var_conv = tf.get_variable('var', [out_ch], \n",
    "            initializer=tf.constant_initializer(1))\n",
    "        gamma_conv = tf.get_variable('gamma', [out_ch], \n",
    "            initializer=tf.constant_initializer(1))\n",
    "        beta_conv = tf.get_variable('beta', [out_ch], \n",
    "            initializer=tf.constant_initializer(0))\n",
    "        output = tf.nn.batch_normalization(prev_layer, mu_conv, \n",
    "            var_conv, beta_conv, gamma_conv, eps, name='batch_norm')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch norm looks normal. Note that we will need to get a bunch of variables here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(prev_layer, name_scope='conv'):\n",
    "    with tf.variable_scope(name_scope) as scope:\n",
    "        return tf.nn.relu(prev_layer, name='a')\n",
    "def maxpool(prev_layer, k_h=1, k_w=1, d_h=1, d_w=1, name_scope='conv'):\n",
    "    with tf.variable_scope(name_scope) as scope:\n",
    "        return tf.nn.max_pool(prev_layer, \n",
    "                [1, k_h, k_w, 1], [1, d_h, d_w, 1], padding='VALID', name='maxpool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing about these functions is that they don't use any weights, so we should be able to directly use Keras analgoues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Understand how Keras does things \n",
    "## Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the Keras Conv2D object. It seems to have a get_weights parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Conv2D(16, (64,1), strides=(2,1))\n",
    "c.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, I think we need to pass an Input through it to get it to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 1, 16)\n",
      "(16,)\n",
      "[[[-0.00015322  0.03328478  0.0431439   0.05665177  0.02174677  0.07000305\n",
      "    0.03909661 -0.02369325 -0.07219765  0.00808635 -0.04132511  0.01037094\n",
      "   -0.06979632 -0.02060135 -0.05271819  0.01664291]]]\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(None,1,1))\n",
    "c(inp)\n",
    "weights = c.get_weights()\n",
    "print(weights[0].shape)\n",
    "print(weights[1].shape)\n",
    "print(weights[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but this is a list, rather than a dictionary, so I have to guess which ones they are. However, by the looks of it, the first one is the weights, and the second is the biases.\n",
    "\n",
    "The Conv2D object also has a set_weights function, lets see what happens if we pass in the Conv1 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.41206488,  0.33841759, -0.05745466,  0.27979866,  0.19388007,\n",
       "          0.14923079, -0.74014872, -0.32045165,  0.59633714,  0.03676248,\n",
       "         -0.50728828, -0.1975117 , -0.22688788, -0.12416738, -0.1477133 ,\n",
       "         -0.14983156]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.set_weights([param_G['conv1']['weights'],param_G['conv1']['biases']])\n",
    "c.get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, that looks like we have set the weights correctly. Let's move onto Batch Norm\n",
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore batch norm, lets do the same as before, and see what the weights look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16,), (16,), (16,), (16,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = BatchNormalization()\n",
    "bn(c(inp))\n",
    "weights = bn.get_weights()\n",
    "[w.shape for w in weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately all the weights for batch normalization are the same Shape! Let's consult the Keras Source code to figure out what order they should be in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BatchNormalization??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `build` function, it seems the order is \n",
    "`gamma`,`beta`,`moving_mean`,`moving_variance`\n",
    "Let's compare this to the keys in the weight dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gamma', 'weights', 'biases', 'beta', 'var', 'mean'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_G['conv1'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, the mapping seems pretty straight forward. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.67092448,  0.70485812,  1.07762814,  1.07327878,  0.99859923,\n",
       "         1.43394423,  0.98132694,  0.82170153,  1.76054716,  1.30240929,\n",
       "         0.61374092,  0.69179982,  1.39582741,  0.89855939,  0.78170842,\n",
       "         0.88884467], dtype=float32),\n",
       " array([ 0.22135185,  0.0341051 ,  0.18717989,  0.00313667,  0.09816235,\n",
       "        -0.01616378,  0.48686007,  0.13595471,  0.27616981,  0.03256222,\n",
       "         0.58677894,  0.2408203 ,  0.0112493 ,  0.30446413,  0.23332365,\n",
       "         0.34096041], dtype=float32),\n",
       " array([-0.25211978,  3.3069694 ,  1.29265058,  0.3468363 , -7.58555794,\n",
       "        -0.4582119 ,  0.36731982,  0.54561132,  0.08063642,  0.20060934,\n",
       "        -0.39500237,  0.4565326 , -0.47915456,  0.28680989,  1.13165963,\n",
       "         0.64741123], dtype=float32),\n",
       " array([ 25892.19140625,  28977.63671875,   9814.6171875 ,  27940.69335938,\n",
       "         52304.66796875,  34629.9140625 ,  24162.2578125 ,  37237.19921875,\n",
       "         38663.5234375 ,   5816.80810547,    764.2232666 ,  17119.06835938,\n",
       "         45902.73828125,  14777.60449219,  21598.45507812,   1602.12036133], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.set_weights([param_G['conv1'][name] for name in ['gamma','beta','mean','var']])\n",
    "bn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.], dtype=float32), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.], dtype=float32), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.], dtype=float32), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.67092448,  0.70485812,  1.07762814,  1.07327878,  0.99859923,\n",
       "         1.43394423,  0.98132694,  0.82170153,  1.76054716,  1.30240929,\n",
       "         0.61374092,  0.69179982,  1.39582741,  0.89855939,  0.78170842,\n",
       "         0.88884467], dtype=float32),\n",
       " array([ 0.22135185,  0.0341051 ,  0.18717989,  0.00313667,  0.09816235,\n",
       "        -0.01616378,  0.48686007,  0.13595471,  0.27616981,  0.03256222,\n",
       "         0.58677894,  0.2408203 ,  0.0112493 ,  0.30446413,  0.23332365,\n",
       "         0.34096041], dtype=float32),\n",
       " array([-0.25211978,  3.3069694 ,  1.29265058,  0.3468363 , -7.58555794,\n",
       "        -0.4582119 ,  0.36731982,  0.54561132,  0.08063642,  0.20060934,\n",
       "        -0.39500237,  0.4565326 , -0.47915456,  0.28680989,  1.13165963,\n",
       "         0.64741123], dtype=float32),\n",
       " array([ 25892.19140625,  28977.63671875,   9814.6171875 ,  27940.69335938,\n",
       "         52304.66796875,  34629.9140625 ,  24162.2578125 ,  37237.19921875,\n",
       "         38663.5234375 ,   5816.80810547,    764.2232666 ,  17119.06835938,\n",
       "         45902.73828125,  14777.60449219,  21598.45507812,   1602.12036133], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = BatchNormalization()\n",
    "bn(c(inp))\n",
    "print(bn.get_weights())\n",
    "K.set_value(bn.gamma, param_G['conv1']['gamma'])\n",
    "K.set_value(bn.beta, param_G['conv1']['beta'])\n",
    "K.set_value(bn.moving_mean, param_G['conv1']['mean'])\n",
    "K.set_value(bn.moving_variance, param_G['conv1']['var'])\n",
    "bn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BatchNormalization??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, that worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Implement Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to set weights, the rest was just a simple search to line up all the varibales.\n",
    "I've recreated the soundnet `ops.py` functions here so I can just copy the `models.py` model description. \n",
    "However, Every conv has a BatchNorm and a ReLu, so I'm going to roll all that into one function. See below (as well as the padding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_conv_2d(prev_layer, in_ch, out_ch, k_h=1,\n",
    "                 k_w=1, d_h=1, d_w=1,p_h=0, p_w=0, pad='valid',\n",
    "                 name_scope='conv1', weight_dict=None, eps=1e-5, bn_act=True):\n",
    "    if pad=='valid':\n",
    "        padded_input = ZeroPadding2D((p_h, p_w))(prev_layer)\n",
    "    else:\n",
    "        padded_input = prev_layer\n",
    "    \n",
    "    weights = weight_dict[name_scope]\n",
    "    \n",
    "    conv = Conv2D(out_ch, (k_h,k_w),\n",
    "               strides=(d_h, d_w))\n",
    "    # Need to pass input through so the layer knows its shape. \n",
    "    convOut = conv(padded_input)\n",
    "    \n",
    "    conv.set_weights([weights['weights'], weights['biases']])\n",
    "\n",
    "    # Break if we don't need to add activation or BatchNorm. \n",
    "    if not bn_act:\n",
    "        return convOut\n",
    "    \n",
    "    bn = BatchNormalization(epsilon=eps)\n",
    "    bnOut = bn(convOut)\n",
    "    \n",
    "    bn.set_weights([weights[k] for k in ['gamma','beta','mean','var']])\n",
    "    act = Activation('relu')\n",
    "    rOut = act(bnOut)\n",
    "    \n",
    "    return rOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to add a few things to make this work with the entire model. This is because layer 'conv_8' is special and doesn't have a batch norm or relu on its output. \n",
    "\n",
    "The maxpooling code is a straightforward port. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keras_maxpool(prev, k_h=1, k_w=1, d_h=1, d_w=1):\n",
    "    return MaxPooling2D(pool_size=(k_h,k_w), strides=(d_h,d_w))(prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Putting it together\n",
    "\n",
    "No let's go and run the code. Keras should complain if we get the dimensions wrong. (This happened to me in the first iteration, but I was able to fix it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_2:0' shape=(?, ?, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(None,1,1))\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights\n",
    "inp = Input(shape=(None, 1, 1))\n",
    "# Stream one: conv1 ~ conv7\n",
    "x1 = keras_conv_2d(inp, 1, 16, k_h=64, d_h=2, p_h=32, name_scope='conv1', weight_dict=param_G)\n",
    "\n",
    "x2 = keras_maxpool(x1, k_h=8, d_h=8)\n",
    "\n",
    "x3= keras_conv_2d(x2, 16, 32, k_h=32, d_h=2, p_h=16, name_scope='conv2', weight_dict=param_G)\n",
    "\n",
    "x4 = keras_maxpool(x3, k_h=8, d_h=8)\n",
    "\n",
    "x5 = keras_conv_2d(x4, 32, 64, k_h=16, d_h=2, p_h=8, name_scope='conv3',weight_dict=param_G)\n",
    "\n",
    "x6 = keras_conv_2d(x5, 64, 128, k_h=8, d_h=2, p_h=4, name_scope='conv4',weight_dict=param_G)\n",
    "\n",
    "x7 = keras_conv_2d(x6, 128, 256, k_h=4, d_h=2, p_h=2, name_scope='conv5',weight_dict=param_G)\n",
    "\n",
    "x8 = keras_maxpool(x7, k_h=4, d_h=4)\n",
    "\n",
    "x9 = keras_conv_2d(x8, 256, 512, k_h=4, d_h=2, p_h=2, name_scope='conv6',weight_dict=param_G)\n",
    "\n",
    "x = keras_conv_2d(x9, 512, 1024, k_h=4, d_h=2, p_h=2, name_scope='conv7',weight_dict=param_G)\n",
    "\n",
    "# Split one: conv8, conv8_2\n",
    "imageNet = keras_conv_2d(x, 1024, 1000, k_h=8, d_h=2,\n",
    "                     name_scope='conv8',weight_dict=param_G,\n",
    "                     bn_act=False)\n",
    "places = keras_conv_2d(x, 1024, 401, k_h=8, d_h=2,\n",
    "                   name_scope='conv8_2',weight_dict=param_G,\n",
    "                   bn_act=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct 3 models from this. One model is the \"features\" we could use for transfer learning, while the other 2 models are predictions of sound related to the places and imagenet competitions classes. Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagnetModel = KModel(inputs=inp, outputs=imageNet)\n",
    "placesModel = KModel(inputs=inp, outputs=places)\n",
    "features = KModel(inputs=inp, outputs=x)\n",
    "baseFeatures = KModel(inputs=inp, outputs=x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Test it's the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that we have build the same thing as the Tensorflow implementation, we need to be running this notebook in a directory which has the contents of https://github.com/eborboihuc/SoundNet-tensorflow in it.\n",
    "\n",
    "Let's also load in some data that I have handy at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnvial\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils as np_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data = np.load('linerData.npy')\n",
    "data.shape\n",
    "\n",
    "data = data.reshape((-1, 176400,1, 1))\n",
    "labels = np_utils.to_categorical(np.load('linerLabels.npy').reshape((-1, 1))).reshape((-1,2))\n",
    "\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(data, labels)\n",
    "\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test1, y_test1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets compile our features model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#baseFeatures.compile('adam','categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_valid = x_valid.reshape(170,176400,1,1)\n",
    "\n",
    "test_set = x_valid[0:2,:,:,:].reshape(2,176400,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureResult = features.predict(test_set, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440.16888"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(featureResult)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the Tensorflow model.\n",
    "Note: Make sure you run `model.load` after `sesssion.run(init)`. Otherwise you will re-initialise all the variables, destroying their pretrained weights! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 2\n",
      "name_scope : SoundNet\n",
      "sample_rate : 22050\n",
      "eps : 1e-05\n",
      "load_size : 441000\n",
      "Assign pretrain model gamma to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv1\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv3\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv8_2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv8_2\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv5\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv7\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv8\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv8\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv4\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model gamma to conv6\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model weights to conv6\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model biases to conv6\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model beta to conv6\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model var to conv6\n",
      "assigned diff = 0.0\n",
      "Assign pretrain model mean to conv6\n",
      "assigned diff = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model as SoundNet\n",
    "\n",
    "\n",
    "# Init. Session\n",
    "sess_config = tf.ConfigProto()\n",
    "sess_config.allow_soft_placement=True\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "\n",
    "session = tf.Session(config=sess_config)\n",
    "\n",
    "# Load pre-trained model\n",
    "G_name = './models/sound8.npy'\n",
    "param_G = np.load(G_name, encoding='latin1').item()\n",
    "\n",
    "local_config = {\n",
    "            'batch_size': 2,\n",
    "            'eps': 1e-5,\n",
    "            'sample_rate': 22050,\n",
    "            'load_size': 22050*20,\n",
    "            'name_scope': 'SoundNet',\n",
    "}\n",
    "\n",
    "model = SoundNet.Model(session, config=local_config, param_G=param_G)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "session.run(init)\n",
    "\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the `edist` function to calculate the euclidean distance (or norm) of two vectors. This way we can check the approaches are equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def edist(x):\n",
    "    return np.sqrt(np.sum(np.square(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 1, 1024)\n",
      "(2, 6, 1, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoundNetResult = session.run(model.layers[24], \n",
    "                      feed_dict={model.sound_input_placeholder: test_set})\n",
    "\n",
    "print(SoundNetResult.shape)\n",
    "print(featureResult.shape)\n",
    "\n",
    "edist(SoundNetResult-featureResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! The results are the same!\n",
    "\n",
    "We can also check the other layers, or try on more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
